#!/usr/bin/env python3
"""
ğŸ’Š Medication Agent - LangChain ë²„ì „
LangChainë§Œì„ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ì•½ë¬¼ ì •ë³´ ì±—ë´‡
"""

import streamlit as st
import os
import json
from typing import List, Dict, Any
from dotenv import load_dotenv
from datetime import datetime

# LangChain ê´€ë ¨ import
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_qdrant import QdrantVectorStore
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue, MatchAny

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ’Š Medication Agent (LangChain)",
    page_icon="ğŸ’Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .chat-container {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
        max-height: 600px;
        overflow-y: auto;
    }
    .user-message {
        background-color: #007bff;
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 15px;
        margin: 0.5rem 0;
        text-align: right;
        max-width: 80%;
        margin-left: auto;
    }
    .bot-message {
        background-color: white;
        color: #333;
        padding: 0.5rem 1rem;
        border-radius: 15px;
        margin: 0.5rem 0;
        text-align: left;
        max-width: 80%;
        border: 1px solid #ddd;
    }
    .stButton > button {
        width: 100%;
        border-radius: 20px;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def initialize_langchain():
    """LangChain ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
    try:
        # OpenAI ì„¤ì •
        llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.1,
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # Qdrant í´ë¼ì´ì–¸íŠ¸
        qdrant_client = QdrantClient(
            url=os.getenv("QDRANT_URL"),
            api_key=os.getenv("QDRANT_API_KEY")
        )
        
        # VectorStore ìƒì„± (ê³µì‹ ë¬¸ì„œ ê¸°ì¤€)
        vectorstore = QdrantVectorStore(
            client=qdrant_client,
            collection_name="product_sections",
            embedding=embeddings
        )
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        prompt_template = PromptTemplate(
            input_variables=["context", "question"],
            template="""
ë‹¹ì‹ ì€ í•œêµ­ì˜ ì•½ë¬¼ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹ì•½ì²˜ ê³µê³µë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì°¸ê³  ì •ë³´:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€: í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì•½ë¬¼ì˜ íš¨ëŠ¥, ìš©ë²•, ì£¼ì˜ì‚¬í•­, ë¶€ì‘ìš© ë“±ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
        )
        
        # RetrievalQA ì²´ì¸ ìƒì„±
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
            chain_type_kwargs={"prompt": prompt_template},
            return_source_documents=True
        )
        
        # ë””ë²„ê¹…: Qdrantì—ì„œ ì§ì ‘ ê²€ìƒ‰í•˜ì—¬ ë©”íƒ€ë°ì´í„° í™•ì¸
        try:
            # ìƒ˜í”Œ ê²€ìƒ‰ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° êµ¬ì¡° í™•ì¸
            sample_results = qdrant_client.search(
                collection_name="product_sections",
                query_vector=embeddings.embed_query("íƒ€ì´ë ˆë†€"),
                limit=1,
                with_payload=True
            )
            if sample_results:
                st.write(f"ğŸ” ìƒ˜í”Œ ê²€ìƒ‰ ê²°ê³¼ ë©”íƒ€ë°ì´í„°: {sample_results[0].payload}")
        except Exception as e:
            st.write(f"âŒ ìƒ˜í”Œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # Qdrant ì»¬ë ‰ì…˜ ìƒíƒœ í™•ì¸
        try:
            collection_info = qdrant_client.get_collection("product_sections")
            st.write(f"ğŸ“Š Qdrant ì»¬ë ‰ì…˜ ì •ë³´: {collection_info}")
        except Exception as e:
            st.write(f"âŒ Qdrant ì»¬ë ‰ì…˜ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        return qa_chain, vectorstore
        
    except Exception as e:
        st.error(f"LangChain ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None, None

def get_dummy_data():
    """ë”ë¯¸ ë°ì´í„° (í…ŒìŠ¤íŠ¸ìš©)"""
    return [
        {
            "score": 0.95,
            "item_name": "íƒ€ì´ë ˆë†€ì •500ë°€ë¦¬ê·¸ëŒ(ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ)",
            "entp_name": "í•œêµ­ì¡´ìŠ¨ì•¤ë“œì¡´ìŠ¨íŒë§¤(ìœ )",
            "section": "efficacy",
            "aliases": ["íƒ€ì´ë ˆë†€"],
            "ingredients": ["ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ"],
            "text": "ì´ ì•½ì€ ê°ê¸°ë¡œ ì¸í•œ ë°œì—´ ë° ë™í†µ(í†µì¦), ë‘í†µ, ì‹ ê²½í†µ, ê·¼ìœ¡í†µ, ì›”ê²½í†µ, ì—¼ì¢Œí†µ(ì‚” í†µì¦), ì¹˜í†µ, ê´€ì ˆí†µ, ë¥˜ë§ˆí‹°ì–‘ ë™í†µ(í†µì¦)ì— ì‚¬ìš©í•©ë‹ˆë‹¤.",
            "update_de": "2024-11-25",
            "is_otc": True
        }
    ]

def check_qdrant_data():
    """Qdrant ë°ì´í„° ìƒíƒœ í™•ì¸"""
    try:
        qdrant_client = QdrantClient(
            url=os.getenv("QDRANT_URL"),
            api_key=os.getenv("QDRANT_API_KEY")
        )
        
        # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
        collection_info = qdrant_client.get_collection("product_sections")
        st.write(f"ğŸ“Š ì»¬ë ‰ì…˜ ì •ë³´: {collection_info}")
        
        # ë°ì´í„° ê°œìˆ˜ í™•ì¸
        scroll_result = qdrant_client.scroll(
            collection_name="product_sections",
            limit=1
        )
        st.write(f"ğŸ“Š ì´ ë°ì´í„° ê°œìˆ˜: {scroll_result[1]}")
        
        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
        if scroll_result[0]:
            sample_point = scroll_result[0][0]
            st.write(f"ğŸ“‹ ìƒ˜í”Œ ë°ì´í„° payload: {sample_point.payload}")
            st.write(f"ğŸ“‹ ìƒ˜í”Œ ë°ì´í„° vector ê¸¸ì´: {len(sample_point.vector) if sample_point.vector else 'None'}")
            
            # ë²¡í„°ê°€ ì—†ìœ¼ë©´ ê²½ê³ 
            if not sample_point.vector:
                st.warning("âš ï¸ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤. DB ì´ˆê¸°í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        return True
    except Exception as e:
        st.write(f"âŒ Qdrant ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
        return False

def initialize_qdrant_db():
    """Qdrant ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ì»¬ë ‰ì…˜ ì¬ìƒì„±)"""
    try:
        qdrant_client = QdrantClient(
            url=os.getenv("QDRANT_URL"),
            api_key=os.getenv("QDRANT_API_KEY")
        )
        
        # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ
        try:
            qdrant_client.delete_collection("product_sections")
            st.write("ğŸ—‘ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œë¨")
        except Exception as e:
            st.write(f"ğŸ“ ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ì—†ê±°ë‚˜ ì‚­ì œ ì‹¤íŒ¨: {e}")
        
        # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
        qdrant_client.create_collection(
            collection_name="product_sections",
            vectors_config={"size": 1536, "distance": "Cosine"}
        )
        st.success("âœ… ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±ë¨")
        
        st.info("ğŸ’¡ ì´ì œ 'ë°ì´í„° ì¬ì¸ë±ì‹±' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”!")
        
        return True
    except Exception as e:
        st.error(f"âŒ DB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def reindex_qdrant_data():
    """Qdrant ë°ì´í„° ì¬ì¸ë±ì‹±"""
    try:
        # JSON íŒŒì¼ì—ì„œ ë°ì´í„° ì½ê¸° (ìƒìœ„ í´ë”ì—ì„œ)
        json_path = "../all_drug_data.json"
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        st.write(f"ğŸ“Š JSON ë°ì´í„° ë¡œë“œë¨: {len(data)}ê°œ í•­ëª©")
        
        # Qdrant í´ë¼ì´ì–¸íŠ¸
        qdrant_client = QdrantClient(
            url=os.getenv("QDRANT_URL"),
            api_key=os.getenv("QDRANT_API_KEY")
        )
        
        # Embeddings ì´ˆê¸°í™”
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° ì²˜ë¦¬
        st.write(f"ğŸ“Š ë°ì´í„° íƒ€ì…: {type(data)}")
        if isinstance(data, dict):
            st.write(f"ğŸ“Š ë”•ì…”ë„ˆë¦¬ í‚¤: {list(data.keys())}")
            
            # ëª¨ë“  ì•½ë¬¼ ë°ì´í„° ìˆ˜ì§‘
            all_items = []
            for drug_name, drug_list in data.items():
                if isinstance(drug_list, list):
                    for drug_item in drug_list:
                        # ì•½ë¬¼ëª…ì„ ë³„ì¹­ìœ¼ë¡œ ì¶”ê°€
                        if isinstance(drug_item, dict):
                            drug_item['aliases'] = drug_item.get('aliases', []) + [drug_name]
                        all_items.append(drug_item)
            
            items_to_process = all_items
            st.write(f"ğŸ“Š ì²˜ë¦¬í•  ì•½ë¬¼ ìˆ˜: {len(items_to_process)}")
        else:
            st.error("âŒ ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœê°€ ì•„ë‹™ë‹ˆë‹¤!")
            return False
        
        # í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
        points = []
            
        for i, item in enumerate(items_to_process):
            try:
                # ê° ì„¹ì…˜ë³„ë¡œ ë³„ë„ì˜ í¬ì¸íŠ¸ ìƒì„±
                item_name = item.get('itemName', '')
                
                # ì„¹ì…˜ë³„ ë°ì´í„° ì •ì˜
                sections = [
                    ("efficacy", item.get('efcyQesitm', ''), "íš¨ëŠ¥/íš¨ê³¼"),
                    ("usage", item.get('useMethodQesitm', ''), "ìš©ë²•/ìš©ëŸ‰"),
                    ("warning", item.get('atpnWarnQesitm', ''), "ì£¼ì˜ì‚¬í•­ ê²½ê³ "),
                    ("precaution", item.get('atpnQesitm', ''), "ì£¼ì˜ì‚¬í•­"),
                    ("interaction", item.get('intrcQesitm', ''), "ìƒí˜¸ì‘ìš©"),
                    ("side_effect", item.get('seQesitm', ''), "ë¶€ì‘ìš©"),
                    ("storage", item.get('depositMethodQesitm', ''), "ë³´ê´€ë²•")
                ]
                
                for section_idx, (section_key, section_text, section_name) in enumerate(sections):
                    # None ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
                    if section_text is None:
                        section_text = ""
                    
                    if section_text.strip():  # ë¹ˆ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì²˜ë¦¬
                        # ì„¹ì…˜ë³„ í…ìŠ¤íŠ¸ ìƒì„±
                        text = f"{item_name} {section_text}"
                        
                        # ì„ë² ë”© ìƒì„±
                        vector = embeddings.embed_query(text)
                        
                        # í¬ì¸íŠ¸ ìƒì„± (ì„¹ì…˜ë³„ë¡œ ê³ ìœ  ID)
                        point_id = i * 10 + section_idx  # ì„¹ì…˜ë³„ ê³ ìœ  ID
                        point = {
                            "id": point_id,
                            "vector": vector,
                            "payload": {
                                "item_name": item_name,
                                "section": section_key,
                                "section_name": section_name,
                                "text": text,
                                "ingredients": item.get("ingredients", []),
                                "aliases": item.get("aliases", [])
                            }
                        }
                        points.append(point)
                
                st.write(f"âœ… {i+1}ë²ˆì§¸ í•­ëª© ì²˜ë¦¬ë¨: {item_name[:30]}... (ì„¹ì…˜ë³„ë¡œ ë¶„ë¦¬)")
                
            except Exception as e:
                st.write(f"âŒ {i+1}ë²ˆì§¸ í•­ëª© ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                st.write(f"ğŸ“‹ ì‹¤íŒ¨í•œ í•­ëª© ë°ì´í„°: {item}")
        
        # Qdrantì— ì—…ë¡œë“œ
        if points:
            qdrant_client.upsert(
                collection_name="product_sections",
                points=points
            )
            st.success(f"âœ… {len(points)}ê°œ í•­ëª© ì—…ë¡œë“œ ì™„ë£Œ!")
        
        return True
    except Exception as e:
        st.error(f"âŒ ì¬ì¸ë±ì‹± ì‹¤íŒ¨: {e}")
        return False

def format_source_info(source, index):
    """ì†ŒìŠ¤ ì •ë³´ë¥¼ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # LangChain Document ê°ì²´ì¸ ê²½ìš°
        if hasattr(source, 'metadata') and hasattr(source, 'page_content'):
            metadata = source.metadata
            content = source.page_content
            
            # Qdrantì—ì„œ ì§ì ‘ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            try:
                qdrant_client = QdrantClient(
                    url=os.getenv("QDRANT_URL"),
                    api_key=os.getenv("QDRANT_API_KEY")
                )
                
                # _idê°€ ìˆìœ¼ë©´ í•´ë‹¹ í¬ì¸íŠ¸ ì¡°íšŒ
                if '_id' in metadata:
                    point = qdrant_client.retrieve(
                        collection_name="product_sections",
                        ids=[metadata['_id']]
                    )
                    if point:
                        payload = point[0].payload
                        content = payload.get('text', content)
                        item_name = payload.get('item_name', metadata.get('item_name', f'ë¬¸ì„œ {index}'))
                        section_key = payload.get('section', metadata.get('section', 'N/A'))
                        section_name = payload.get('section_name', 'N/A')
                        # ì ìˆ˜ëŠ” ë©”íƒ€ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¤ê¸° (LangChainì—ì„œ ì œê³µ)
                        score = metadata.get('score', 'N/A')
                        
                        # ì„¹ì…˜ í‘œì‹œ í˜•ì‹ ê²°ì •
                        if section_name != 'N/A':
                            section = f"{section_key} ({section_name})"
                        else:
                            section = section_key
                    else:
                        item_name = metadata.get('item_name', f'ë¬¸ì„œ {index}')
                        section_key = metadata.get('section', 'N/A')
                        section_name = metadata.get('section_name', 'N/A')
                        score = metadata.get('score', 'N/A')
                        
                        # ì„¹ì…˜ í‘œì‹œ í˜•ì‹ ê²°ì •
                        if section_name != 'N/A':
                            section = f"{section_key} ({section_name})"
                        else:
                            section = section_key
                else:
                    # _idê°€ ì—†ìœ¼ë©´ ë©”íƒ€ë°ì´í„°ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
                    item_name = metadata.get('item_name', f'ë¬¸ì„œ {index}')
                    section_key = metadata.get('section', 'N/A')
                    section_name = metadata.get('section_name', 'N/A')
                    score = metadata.get('score', 'N/A')
                    
                    # ì„¹ì…˜ í‘œì‹œ í˜•ì‹ ê²°ì •
                    if section_name != 'N/A':
                        section = f"{section_key} ({section_name})"
                    else:
                        section = section_key
                    
            except Exception as e:
                # Qdrant ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ë©”íƒ€ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                item_name = metadata.get('item_name', f'ë¬¸ì„œ {index}')
                section_key = metadata.get('section', 'N/A')
                section_name = metadata.get('section_name', 'N/A')
                score = metadata.get('score', 'N/A')
                content = content if content else f"Qdrant ì¡°íšŒ ì‹¤íŒ¨: {e}"
                
                # ì„¹ì…˜ í‘œì‹œ í˜•ì‹ ê²°ì •
                if section_name != 'N/A':
                    section = f"{section_key} ({section_name})"
                else:
                    section = section_key
            
            return {
                "title": item_name,
                "section": section,
                "score": score,
                "content": content[:300] + "..." if len(content) > 300 else content,
                "type": "langchain_document"
            }
        # ì¼ë°˜ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
        elif isinstance(source, dict):
            st.write(f"ğŸ“‹ ë”•ì…”ë„ˆë¦¬ í‚¤: {list(source.keys())}")
            return {
                "title": source.get('item_name', f'ë¬¸ì„œ {index}'),
                "section": source.get('section', 'N/A'),
                "score": source.get('score', 'N/A'),
                "content": source.get('text', 'N/A')[:300] + "..." if len(source.get('text', '')) > 300 else source.get('text', 'N/A'),
                "type": "dict"
            }
        # ê¸°íƒ€ ê²½ìš°
        else:
            st.write(f"ğŸ“‹ ê¸°íƒ€ íƒ€ì…: {str(source)[:100]}...")
            return {
                "title": f'ë¬¸ì„œ {index}',
                "section": 'N/A',
                "score": 'N/A',
                "content": str(source)[:300] + "..." if len(str(source)) > 300 else str(source),
                "type": "unknown"
            }
    except Exception as e:
        st.write(f"âŒ í¬ë§·íŒ… ì˜¤ë¥˜: {str(e)}")
        return {
            "title": f'ë¬¸ì„œ {index} (ì˜¤ë¥˜)',
            "section": 'N/A',
            "score": 'N/A',
            "content": f"í¬ë§·íŒ… ì˜¤ë¥˜: {str(e)}",
            "type": "error"
        }

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

def add_message(role: str, content: str, sources: List[Dict] = None):
    """ë©”ì‹œì§€ ì¶”ê°€"""
    timestamp = datetime.now().strftime("%H:%M")
    message = {
        "role": role,
        "content": content,
        "timestamp": timestamp,
        "sources": sources or []
    }
    st.session_state.messages.append(message)

def main():
    """ë©”ì¸ ì•±"""
    initialize_session_state()
    
    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸ’Š Medication Agent</h1>', unsafe_allow_html=True)
    st.markdown("### ğŸ¤– LangChain ê¸°ë°˜ AI ì•½ë¬¼ ì •ë³´ ì±—ë´‡")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ”§ ì„¤ì •")
        
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ í† ê¸€
        test_mode = st.checkbox("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ", help="API ì—†ì´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‹¤í–‰")
        
        # ê²€ìƒ‰ ì˜µì…˜
        st.subheader("ê²€ìƒ‰ ì˜µì…˜")
        
        # ê²°ê³¼ ìˆ˜ ì„¤ì •
        k = st.slider("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 1, 10, 3)
        
        st.markdown("---")
        
        # ëŒ€í™” ì´ˆê¸°í™”
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", type="secondary"):
            st.session_state.messages = []
            st.session_state.chat_history = []
            st.rerun()
        
        st.markdown("---")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        
        if test_mode:
            st.success("âœ… í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™œì„±í™”")
        else:
            # LangChain ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
            try:
                qa_chain, vectorstore = initialize_langchain()
                if qa_chain:
                    st.success("âœ… LangChain ì •ìƒ")
                else:
                    st.error("âŒ LangChain ì´ˆê¸°í™” ì‹¤íŒ¨")
            except Exception as e:
                st.error(f"âŒ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
            
            # Qdrant ë°ì´í„° í™•ì¸ ë²„íŠ¼
            if st.button("ğŸ” Qdrant ë°ì´í„° í™•ì¸", type="secondary"):
                check_qdrant_data()
            
            # DB ì´ˆê¸°í™” ë²„íŠ¼
            if st.button("ğŸ—„ï¸ DB ì´ˆê¸°í™”", type="secondary"):
                initialize_qdrant_db()
            
            # ì¬ì¸ë±ì‹± ë²„íŠ¼
            if st.button("ğŸ”„ ë°ì´í„° ì¬ì¸ë±ì‹±", type="secondary"):
                reindex_qdrant_data()
        
        st.markdown("---")
        
        # ì˜ˆì‹œ ì§ˆë¬¸
        st.subheader("ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸")
        example_questions = [
            "íƒ€ì´ë ˆë†€ì˜ íš¨ëŠ¥ì´ ë­”ê°€ìš”?",
            "ì™€íŒŒë¦°ê³¼ í•¨ê»˜ ë³µìš©í•˜ë©´ ì•ˆ ë˜ëŠ” ì•½ì´ ìˆë‚˜ìš”?",
            "ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœì˜ ë¶€ì‘ìš©ì€?",
            "íƒ€ì´ë ˆë†€ ë³µìš©ë²• ì•Œë ¤ì£¼ì„¸ìš”",
            "í˜ˆì••ì•½ ì£¼ì˜ì‚¬í•­ì´ ê¶ê¸ˆí•´ìš”"
        ]
        
        for i, question in enumerate(example_questions):
            if st.button(question, key=f"sidebar_example_{i}"):
                st.session_state.example_question = question
                st.rerun()
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # ì±„íŒ… ì»¨í…Œì´ë„ˆ
        chat_container = st.container()
        
        with chat_container:
            # ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
            for message in st.session_state.messages:
                if message["role"] == "user":
                    st.markdown(f"""
                    <div class="user-message">
                        <strong>ë‚˜:</strong> {message["content"]}
                        <br><small>{message["timestamp"]}</small>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div class="bot-message">
                        <strong>ğŸ’Š AI:</strong> {message["content"]}
                        <br><small>{message["timestamp"]}</small>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ
                    if message.get("sources"):
                        with st.expander("ğŸ“š ì°¸ê³  ì •ë³´"):
                            st.write(f"ğŸ” ì´ {len(message['sources'])}ê°œì˜ ì†ŒìŠ¤ì—ì„œ ê²€ìƒ‰ë¨")
                            
                            for i, source in enumerate(message["sources"][:3], 1):
                                # ë””ë²„ê¹…: ì›ë³¸ ì†ŒìŠ¤ ì •ë³´ ì¶œë ¥
                                st.write(f"ğŸ” ì›ë³¸ ì†ŒìŠ¤ {i} ë©”íƒ€ë°ì´í„°: {source.metadata if hasattr(source, 'metadata') else 'No metadata'}")
                                
                                formatted_source = format_source_info(source, i)
                                
                                st.markdown(f"""
                                **{i}. {formatted_source['title']}**
                                - ğŸ“‚ ì„¹ì…˜: {formatted_source['section']}
                                - ğŸ“Š ì ìˆ˜: {formatted_source['score']}
                                - ğŸ·ï¸ íƒ€ì…: {formatted_source['type']}
                                """)
                                
                                # ë‚´ìš© í‘œì‹œ
                                with st.expander(f"ğŸ“ ë‚´ìš© ë³´ê¸° ({len(formatted_source['content'])}ì)"):
                                    st.text(formatted_source['content'])
                                
                                st.markdown("---")
        
        # ì…ë ¥ ì˜ì—­
        st.markdown("---")
        
        # ì§ˆë¬¸ ì…ë ¥ í•„ë“œ
        user_input = st.text_input(
            "ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
            placeholder="ì˜ˆ: íƒ€ì´ë ˆë†€ì˜ íš¨ëŠ¥ì´ ë­”ê°€ìš”?",
            key="user_input"
        )
        
        # ì˜ˆì‹œ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì „ì†¡
        if 'example_question' in st.session_state and st.session_state.example_question:
            user_input = st.session_state.example_question
            # ìë™ìœ¼ë¡œ ì „ì†¡ ì²˜ë¦¬
            if user_input.strip():
                # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                add_message("user", user_input)
                
                # ì‘ë‹µ ìƒì„±
                with st.spinner("ğŸ” ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    if test_mode:
                        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë”ë¯¸ ì‘ë‹µ
                        ai_response = f"í…ŒìŠ¤íŠ¸ ëª¨ë“œì…ë‹ˆë‹¤. '{user_input}'ì— ëŒ€í•œ ë‹µë³€ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤. ì‹¤ì œë¡œëŠ” LangChainê³¼ Qdrantë¥¼ í†µí•´ ì •í™•í•œ ì•½ë¬¼ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
                        sources = get_dummy_data()
                    else:
                        try:
                            # Qdrantì—ì„œ ì§ì ‘ ê²€ìƒ‰í•˜ì—¬ ì ìˆ˜ í¬í•¨ëœ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                            qdrant_client = QdrantClient(
                                url=os.getenv("QDRANT_URL"),
                                api_key=os.getenv("QDRANT_API_KEY")
                            )
                            embeddings = OpenAIEmbeddings(
                                model="text-embedding-3-small",
                                api_key=os.getenv("OPENAI_API_KEY")
                            )
                            
                            # ì§ì ‘ ê²€ìƒ‰
                            search_results = qdrant_client.search(
                                collection_name="product_sections",
                                query_vector=embeddings.embed_query(user_input),
                                limit=3,
                                with_payload=True
                            )
                            
                            # LangChain Document í˜•íƒœë¡œ ë³€í™˜
                            sources = []
                            for result in search_results:
                                doc = Document(
                                    page_content=result.payload.get('text', ''),
                                    metadata={
                                        'item_name': result.payload.get('item_name', ''),
                                        'section': result.payload.get('section', ''),
                                        'section_name': result.payload.get('section_name', ''),
                                        'score': f"{result.score:.3f}"  # ì ìˆ˜ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                                    }
                                )
                                sources.append(doc)
                            
                            # ì§ì ‘ ê²€ìƒ‰í•œ ê²°ê³¼ë¡œ ì‘ë‹µ ìƒì„± (LangChain QA ì²´ì¸ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                            if sources:
                                # ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ë“¤ì„ ê²°í•©
                                context_text = "\n\n".join([doc.page_content for doc in sources])
                                
                                # OpenAI LLMìœ¼ë¡œ ì§ì ‘ ì‘ë‹µ ìƒì„±
                                llm = ChatOpenAI(
                                    model="gpt-3.5-turbo",
                                    temperature=0.1,
                                    api_key=os.getenv("OPENAI_API_KEY")
                                )
                                
                                prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ì˜ ì•½ë¬¼ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹ì•½ì²˜ ê³µê³µë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì°¸ê³  ì •ë³´:
{context_text}

ì§ˆë¬¸: {user_input}

ë‹µë³€: í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì•½ë¬¼ì˜ íš¨ëŠ¥, ìš©ë²•, ì£¼ì˜ì‚¬í•­, ë¶€ì‘ìš© ë“±ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
                                
                                ai_response = llm.invoke(prompt).content
                            else:
                                ai_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        except Exception as e:
                            ai_response = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                            sources = []
                    
                    # AI ë©”ì‹œì§€ ì¶”ê°€
                    add_message("assistant", ai_response, sources)
                
                # ì‚¬ìš© í›„ ì‚­ì œ
                del st.session_state.example_question
                st.rerun()
        
        # ì „ì†¡ ë²„íŠ¼
        col_a, col_b, col_c = st.columns([1, 1, 1])
        
        with col_b:
            if st.button("ğŸš€ ì „ì†¡", type="primary", use_container_width=True):
                if user_input.strip():
                    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                    add_message("user", user_input)
                    
                    # ì‘ë‹µ ìƒì„±
                    with st.spinner("ğŸ” ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        if test_mode:
                            # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë”ë¯¸ ì‘ë‹µ
                            ai_response = f"í…ŒìŠ¤íŠ¸ ëª¨ë“œì…ë‹ˆë‹¤. '{user_input}'ì— ëŒ€í•œ ë‹µë³€ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤. ì‹¤ì œë¡œëŠ” LangChainê³¼ Qdrantë¥¼ í†µí•´ ì •í™•í•œ ì•½ë¬¼ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."
                            sources = get_dummy_data()
                        else:
                            try:
                                # Qdrantì—ì„œ ì§ì ‘ ê²€ìƒ‰í•˜ì—¬ ì ìˆ˜ í¬í•¨ëœ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                                qdrant_client = QdrantClient(
                                    url=os.getenv("QDRANT_URL"),
                                    api_key=os.getenv("QDRANT_API_KEY")
                                )
                                embeddings = OpenAIEmbeddings(
                                    model="text-embedding-3-small",
                                    api_key=os.getenv("OPENAI_API_KEY")
                                )
                                
                                # ì§ì ‘ ê²€ìƒ‰
                                search_results = qdrant_client.search(
                                    collection_name="product_sections",
                                    query_vector=embeddings.embed_query(user_input),
                                    limit=3,
                                    with_payload=True
                                )
                                
                                # LangChain Document í˜•íƒœë¡œ ë³€í™˜
                                sources = []
                                for result in search_results:
                                    doc = Document(
                                        page_content=result.payload.get('text', ''),
                                        metadata={
                                            'item_name': result.payload.get('item_name', ''),
                                            'section': result.payload.get('section', ''),
                                            'section_name': result.payload.get('section_name', ''),
                                            'score': f"{result.score:.3f}"  # ì ìˆ˜ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                                        }
                                    )
                                    sources.append(doc)
                                
                                # ì§ì ‘ ê²€ìƒ‰í•œ ê²°ê³¼ë¡œ ì‘ë‹µ ìƒì„± (LangChain QA ì²´ì¸ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
                                if sources:
                                    # ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ë“¤ì„ ê²°í•©
                                    context_text = "\n\n".join([doc.page_content for doc in sources])
                                    
                                    # OpenAI LLMìœ¼ë¡œ ì§ì ‘ ì‘ë‹µ ìƒì„±
                                    llm = ChatOpenAI(
                                        model="gpt-3.5-turbo",
                                        temperature=0.1,
                                        api_key=os.getenv("OPENAI_API_KEY")
                                    )
                                    
                                    prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ì˜ ì•½ë¬¼ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹ì•½ì²˜ ê³µê³µë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì°¸ê³  ì •ë³´:
{context_text}

ì§ˆë¬¸: {user_input}

ë‹µë³€: í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì•½ë¬¼ì˜ íš¨ëŠ¥, ìš©ë²•, ì£¼ì˜ì‚¬í•­, ë¶€ì‘ìš© ë“±ì„ ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
                                    
                                    ai_response = llm.invoke(prompt).content
                                    
                                    # ì†ŒìŠ¤ ì •ë³´ í™•ì¸ (ê°„ë‹¨í•œ ë””ë²„ê¹…)
                                    st.write(f"ğŸ” ê²€ìƒ‰ëœ ì†ŒìŠ¤ ìˆ˜: {len(sources)}")
                                else:
                                    ai_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            except Exception as e:
                                ai_response = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                                sources = []
                        
                        # AI ë©”ì‹œì§€ ì¶”ê°€
                        add_message("assistant", ai_response, sources)
                    
                    # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                    st.rerun()
                else:
                    st.error("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        with col_c:
            if st.button("ğŸ² ëœë¤ ì§ˆë¬¸", use_container_width=True):
                random_questions = [
                    "íƒ€ì´ë ˆë†€ì˜ íš¨ëŠ¥ì´ ë­”ê°€ìš”?",
                    "ì™€íŒŒë¦° ìƒí˜¸ì‘ìš©ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
                    "ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ ë¶€ì‘ìš©ì€?",
                    "í˜ˆì••ì•½ ì£¼ì˜ì‚¬í•­ì´ ê¶ê¸ˆí•´ìš”",
                    "ê°ê¸°ì•½ ë³µìš©ë²• ì•Œë ¤ì£¼ì„¸ìš”"
                ]
                import random
                st.session_state.example_question = random.choice(random_questions)
                st.rerun()
    
    with col2:
        st.markdown("### ğŸ“ˆ ëŒ€í™” í†µê³„")
        st.metric("ì´ ë©”ì‹œì§€", len(st.session_state.messages))
        st.metric("ì‚¬ìš©ì ë©”ì‹œì§€", len([m for m in st.session_state.messages if m["role"] == "user"]))
        st.metric("AI ì‘ë‹µ", len([m for m in st.session_state.messages if m["role"] == "assistant"]))
        
        st.markdown("---")
        
        st.markdown("### ğŸ¯ ì¶”ì²œ ì§ˆë¬¸")
        recommended_questions = [
            "íƒ€ì´ë ˆë†€ íš¨ëŠ¥",
            "ì™€íŒŒë¦° ìƒí˜¸ì‘ìš©", 
            "ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ ë¶€ì‘ìš©",
            "í˜ˆì••ì•½ ì£¼ì˜ì‚¬í•­",
            "ê°ê¸°ì•½ ë³µìš©ë²•"
        ]
        
        for i, question in enumerate(recommended_questions):
            if st.button(f"ğŸ’¡ {question}", key=f"recommend_{i}"):
                st.session_state.example_question = question
                st.rerun()
        
        st.markdown("---")
        
        st.markdown("### ğŸ”§ LangChain ì¥ì ")
        st.markdown("""
        - **ê°„ë‹¨í•œ êµ¬ì¡°**: FastAPI ì—†ì´ ì§ì ‘ ì—°ê²°
        - **ë‚´ì¥ í”„ë¡¬í”„íŠ¸**: ìë™ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
        - **ì²´ì¸ ê¸°ë°˜**: ë³µì¡í•œ ë¡œì§ì„ ì²´ì¸ìœ¼ë¡œ êµ¬ì„±
        - **ë©”ëª¨ë¦¬ ê´€ë¦¬**: ëŒ€í™” íˆìŠ¤í† ë¦¬ ìë™ ê´€ë¦¬
        """)

if __name__ == "__main__":
    main()
